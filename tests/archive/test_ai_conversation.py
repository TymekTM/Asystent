#!/usr/bin/env python3
"""Test rzeczywistego u≈ºycia function calling przez AI.

Symuluje komunikacjƒô z OpenAI API z dostƒôpnymi funkcjami.
"""

import asyncio
import json
import sys
from datetime import datetime

# Add project paths
sys.path.insert(0, ".")
sys.path.insert(0, "./server")


# Mock database manager
class MockDatabaseManager:
    def get_user_api_key(self, user_id, provider):
        return None

    def log_api_usage(self, *args, **kwargs):
        pass


import unittest.mock

sys.modules["database_manager"] = unittest.mock.MagicMock()
sys.modules["database_manager"].get_database_manager = lambda: MockDatabaseManager()

from server.modules import (
    api_module,
    core_module,
    music_module,
    open_web_module,
    search_module,
    weather_module,
)


class MockOpenAIResponse:
    """Mock OpenAI API response for testing."""

    def __init__(self, function_calls=None, text_response=None):
        self.function_calls = function_calls or []
        self.text_response = text_response or "Mock AI response"

    def to_dict(self):
        return {
            "choices": [
                {
                    "message": {
                        "content": self.text_response,
                        "tool_calls": [
                            {
                                "id": f"call_{i}",
                                "type": "function",
                                "function": {
                                    "name": call["name"],
                                    "arguments": json.dumps(call["arguments"]),
                                },
                            }
                            for i, call in enumerate(self.function_calls)
                        ]
                        if self.function_calls
                        else None,
                    }
                }
            ]
        }


class AIFunctionCallingSimulator:
    """Symuluje pe≈Çny przep≈Çyw function calling z AI."""

    def __init__(self):
        self.modules = {
            "weather_module": weather_module,
            "search_module": search_module,
            "core_module": core_module,
            "music_module": music_module,
            "api_module": api_module,
            "open_web_module": open_web_module,
        }

    def get_openai_functions_schema(self):
        """Generuje schema funkcji w formacie OpenAI."""
        functions = []

        for module_name, module in self.modules.items():
            if hasattr(module, "get_functions"):
                module_functions = module.get_functions()
                for func in module_functions:
                    openai_func = {
                        "type": "function",
                        "function": {
                            "name": f"{module_name}_{func['name']}",
                            "description": func["description"],
                            "parameters": func["parameters"],
                        },
                    }
                    functions.append(openai_func)

        return functions

    async def execute_function_call(self, function_name, arguments, user_id=1):
        """Wykonuje wywo≈Çanie funkcji z AI."""
        # Parse module name and function name
        # Format: weather_module_get_weather -> weather_module, get_weather
        parts = function_name.split("_")
        if len(parts) < 3:
            return {"error": f"Invalid function name format: {function_name}"}

        # Find module name (ends with '_module')
        module_name = None
        func_name_parts = []

        for i, part in enumerate(parts):
            if part == "module" and i > 0:
                module_name = "_".join(parts[: i + 1])
                func_name_parts = parts[i + 1 :]
                break

        if not module_name or not func_name_parts:
            return {"error": f"Cannot parse function name: {function_name}"}

        func_name = "_".join(func_name_parts)

        if module_name not in self.modules:
            return {"error": f"Module {module_name} not found"}

        module = self.modules[module_name]

        if not hasattr(module, "execute_function"):
            return {
                "error": f"Module {module_name} does not support function execution"
            }

        try:
            result = await module.execute_function(func_name, arguments, user_id)
            return result
        except Exception as e:
            return {"error": str(e), "exception_type": type(e).__name__}

    async def simulate_ai_conversation(self, user_query, mock_ai_response):
        """Symuluje pe≈ÇnƒÖ konwersacjƒô z AI u≈ºywajƒÖc function calling."""
        print(f"üë§ U≈ºytkownik: {user_query}")
        print(f"ü§ñ AI zamierza: {mock_ai_response.text_response}")

        if not mock_ai_response.function_calls:
            print("üìù AI nie wywo≈Çuje ≈ºadnych funkcji")
            return mock_ai_response.text_response

        print(f"üîß AI wywo≈Çuje {len(mock_ai_response.function_calls)} funkcji:")

        function_results = []

        for i, func_call in enumerate(mock_ai_response.function_calls, 1):
            print(f"\nüéØ Funkcja {i}: {func_call['name']}")
            print(
                f"üìã Argumenty: {json.dumps(func_call['arguments'], ensure_ascii=False, indent=2)}"
            )

            result = await self.execute_function_call(
                func_call["name"], func_call["arguments"]
            )

            function_results.append(result)

            if result.get("success", False):
                print(f"‚úÖ Sukces: {result.get('message', 'Brak wiadomo≈õci')}")
            else:
                print(f"‚ùå B≈ÇƒÖd: {result.get('error', 'Nieznany b≈ÇƒÖd')}")

        print(f"\nüí¨ AI finalnie odpowiada: {mock_ai_response.text_response}")
        return {
            "ai_response": mock_ai_response.text_response,
            "function_results": function_results,
        }


async def main():
    """G≈Ç√≥wna funkcja testowa."""
    simulator = AIFunctionCallingSimulator()

    print("üß™ TEST RZECZYWISTEGO FUNCTION CALLING Z AI")
    print("=" * 60)

    # Poka≈º dostƒôpne funkcje
    functions_schema = simulator.get_openai_functions_schema()
    print(f"\nüì¶ Dostƒôpnych funkcji dla AI: {len(functions_schema)}")

    for func in functions_schema[:5]:  # Poka≈º pierwsze 5
        name = func["function"]["name"]
        desc = func["function"]["description"]
        print(f"  ‚Ä¢ {name}: {desc}")
    print(f"  ... i {len(functions_schema) - 5} wiƒôcej")

    # Scenariusze testowe
    test_scenarios = [
        {
            "user_query": "Jaka jest pogoda w Warszawie?",
            "ai_response": MockOpenAIResponse(
                function_calls=[
                    {
                        "name": "weather_module_get_weather",
                        "arguments": {"location": "Warsaw", "test_mode": True},
                    }
                ],
                text_response="Sprawdzam pogodƒô w Warszawie...",
            ),
        },
        {
            "user_query": "Ustaw timer na 10 minut i dodaj zadanie do wykonania",
            "ai_response": MockOpenAIResponse(
                function_calls=[
                    {
                        "name": "core_module_set_timer",
                        "arguments": {"duration": "10m", "label": "Timer u≈ºytkownika"},
                    },
                    {
                        "name": "core_module_add_task",
                        "arguments": {
                            "task": "Wykonaj zaplanowane zadanie",
                            "priority": "medium",
                        },
                    },
                ],
                text_response="Ustawi≈Çem timer na 10 minut i doda≈Çem zadanie do listy.",
            ),
        },
        {
            "user_query": "Wyszukaj informacje o AI i otw√≥rz stronƒô OpenAI",
            "ai_response": MockOpenAIResponse(
                function_calls=[
                    {
                        "name": "search_module_search",
                        "arguments": {
                            "query": "artificial intelligence",
                            "test_mode": True,
                        },
                    },
                    {
                        "name": "open_web_module_open_web",
                        "arguments": {"url": "https://openai.com", "test_mode": True},
                    },
                ],
                text_response="Wyszuka≈Çem informacje o AI i otworzy≈Çem stronƒô OpenAI.",
            ),
        },
        {
            "user_query": "Zatrzymaj muzykƒô i sprawd≈∫ aktualny czas",
            "ai_response": MockOpenAIResponse(
                function_calls=[
                    {
                        "name": "music_module_control_music",
                        "arguments": {"action": "pause", "test_mode": True},
                    },
                    {"name": "core_module_get_current_time", "arguments": {}},
                ],
                text_response="Zatrzyma≈Çem muzykƒô i sprawdzi≈Çem aktualny czas.",
            ),
        },
        {
            "user_query": "Dodaj wydarzenie do kalendarza na jutro",
            "ai_response": MockOpenAIResponse(
                function_calls=[
                    {
                        "name": "core_module_add_event",
                        "arguments": {
                            "title": "Spotkanie zaplanowane przez AI",
                            "date": "2025-07-21",
                            "time": "10:00",
                        },
                    }
                ],
                text_response="Doda≈Çem wydarzenie do kalendarza na jutro o 10:00.",
            ),
        },
    ]

    # Uruchom scenariusze
    all_results = []

    for i, scenario in enumerate(test_scenarios, 1):
        print(f"\n{'='*60}")
        print(f"üìã SCENARIUSZ {i}/{len(test_scenarios)}")
        print(f"{'='*60}")

        result = await simulator.simulate_ai_conversation(
            scenario["user_query"], scenario["ai_response"]
        )

        all_results.append(
            {
                "scenario": i,
                "user_query": scenario["user_query"],
                "result": result,
                "timestamp": datetime.now().isoformat(),
            }
        )

    # Podsumowanie
    print(f"\n{'='*60}")
    print("üìä PODSUMOWANIE KO≈ÉCOWE")
    print(f"{'='*60}")

    total_function_calls = sum(
        len(result["result"]["function_results"])
        for result in all_results
        if isinstance(result["result"], dict)
    )

    successful_calls = sum(
        sum(
            1
            for func_result in result["result"]["function_results"]
            if func_result.get("success", False)
        )
        for result in all_results
        if isinstance(result["result"], dict)
    )

    print(f"‚úÖ Scenariuszy przetestowanych: {len(test_scenarios)}")
    print(f"üîß ≈ÅƒÖczna liczba wywo≈Ça≈Ñ funkcji: {total_function_calls}")
    print(f"‚úÖ Udanych wywo≈Ça≈Ñ: {successful_calls}")
    print(f"‚ùå Nieudanych wywo≈Ça≈Ñ: {total_function_calls - successful_calls}")
    print(f"üìà Procent sukcesu: {successful_calls/total_function_calls*100:.1f}%")

    # Zapisz wyniki
    with open("ai_conversation_test_results.json", "w", encoding="utf-8") as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2, default=str)

    print("\nüíæ Szczeg√≥≈Çowe wyniki zapisane do: ai_conversation_test_results.json")


if __name__ == "__main__":
    asyncio.run(main())
