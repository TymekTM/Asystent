# ğŸ¤– GAJA Assistant

[![Coverage](./coverage.svg)](./coverage.svg)
[![Python](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

**Advanced AI-powered voice assistant with user mode system and real-time overlay interface.**

## ğŸš€ Quick Start

### ğŸ³ With Docker (Recommended)

```bash
# Copy environment template
cp .env.example .env
# Edit .env with your API keys

# Start with CPU support
docker-compose up -d

# Or start with GPU support
docker-compose --profile gpu up -d
```

### ğŸ Traditional Python Setup

```bash
# Install dependencies with Poetry
poetry install

# Start client (voice assistant)
poetry run python -m gaja_client.main

# Start server (AI processing)
poetry run python -m gaja_server.main

# Start web UI (configuration)
cd web_ui && python app.py
```

### ğŸ§ª Development Setup

```bash
# Install development dependencies
poetry install --with dev

# Install pre-commit hooks
poetry run pre-commit install

# Run tests
poetry run pytest

# Run linting
poetry run ruff check .
poetry run black --check .
```

For detailed Docker setup, see [README_DOCKER.md](README_DOCKER.md)

## ğŸ“ Project Structure

```
f:\Asystent\
â”œâ”€â”€ ğŸ“¦ src/                 # Source code (new structure)
â”‚   â”œâ”€â”€ gaja_server/        # AI processing server
â”‚   â”œâ”€â”€ gaja_client/        # Voice assistant client
â”‚   â””â”€â”€ gaja_core/          # Shared utilities
â”œâ”€â”€ ğŸ³ docker/              # Docker configuration
â”‚   â”œâ”€â”€ Dockerfile          # Multi-stage build
â”‚   â”œâ”€â”€ nginx.conf          # Reverse proxy config
â”‚   â””â”€â”€ init-db.sql         # Database initialization
â”œâ”€â”€ ğŸ”„ .github/workflows/   # CI/CD pipelines
â”œâ”€â”€ ğŸ™ï¸ client/              # Voice assistant client (legacy)
â”œâ”€â”€ ğŸ§  server/              # AI processing server (legacy)
â”œâ”€â”€ ğŸŒ web_ui/              # Web configuration interface
â”œâ”€â”€ ğŸ¨ overlay/             # Visual status overlay
â”œâ”€â”€ ğŸ”Š audio_modules/       # TTS, STT, wake word detection
â”œâ”€â”€ ğŸ§© modules/             # Feature modules (weather, music, etc.)
â”œâ”€â”€ ğŸ§ª tests/               # Testing utilities
â”‚   â”œâ”€â”€ performance/        # Load and performance tests
â”‚   â”œâ”€â”€ integration/        # Component integration tests
â”‚   â””â”€â”€ debug/              # Debug and diagnostic tools
â”œâ”€â”€ ğŸ­ demos/               # Feature demonstration scripts
â”œâ”€â”€ ğŸ“Š reports/             # Test reports and documentation
â”œâ”€â”€ âš™ï¸ configs/             # Configuration files
â”œâ”€â”€ ğŸ“š docs/                # Documentation
â”œâ”€â”€ ğŸ“ pyproject.toml       # Poetry configuration
â”œâ”€â”€ ğŸ³ docker-compose.yml   # Docker orchestration
â””â”€â”€ ğŸ”§ .pre-commit-config.yaml  # Code quality hooks
```

## âœ¨ Key Features

### ğŸ¯ User Mode System

- **Poor Man Mode**: Free Edge TTS + Local Whisper
- **Paid User Mode**: OpenAI TTS + OpenAI Whisper
- **Enterprise Mode**: Azure TTS + Azure Whisper

### ğŸ™ï¸ Voice Capabilities

- Wake word detection ("Gaja")
- Real-time speech recognition
- Natural language processing
- Text-to-speech responses

### ğŸ–¥ï¸ Interface Options

- Voice-only interaction
- Visual overlay with status
- Web UI for configuration
- Desktop notifications

### ğŸ§  AI Features

- Context-aware conversations
- Memory system with persistence
- Function calling (weather, music, web search)
- Advanced prompt engineering

## ğŸ› ï¸ Installation

### 1. Clone Repository

```bash
git clone <repository-url>
cd GAJA-Assistant
```

### 2. Install Dependencies

```bash
# Core dependencies
pip install -r requirements.txt

# Client dependencies
pip install -r client/requirements_client.txt

# Server dependencies
pip install -r server/requirements_server.txt

# Demo dependencies (optional)
pip install -r demos/requirements_user_modes.txt
```

### 3. Configuration

```bash
# Copy and edit configuration
cp dummy_config.json config.json

# Add your API keys
nano config.json
```

### 4. First Run

```bash
# Run setup wizard
python setup_wizard.py

# Or quick start
python quick_start.py
```

## ğŸ§ª Testing

### Performance Testing

```bash
cd tests/performance
python concurrent_users_test.py    # Full load testing (100-10k users)
python quick_perf_test.py          # Quick performance check
```

### Integration Testing

```bash
cd tests/integration
python test_client_integration.py  # Client compatibility test
```

### Feature Demos

```bash
cd demos
python demo_user_modes.py          # User mode system demo
python demo_enhanced_tts.py        # TTS providers demo
```

## ğŸ“Š Performance

**Tested with concurrent users:**

- âœ… **200 users**: 100% success, <1s response time
- âš ï¸ **1000 users**: 54.5% success (API rate limited)
- ğŸš€ **Peak throughput**: 323.8 requests/second

## ğŸ”§ Development

### Core Modules

- `user_modes.py` - User mode management system
- `audio_modules/enhanced_tts_module.py` - Multi-provider TTS
- `audio_modules/enhanced_whisper_asr.py` - Dynamic ASR
- `auth_system.py` - Authentication and roles
- `mode_integrator.py` - System integration layer
- `mode_test.py` - Simple CLI for checking free vs. paid mode

### Architecture

- **Client-Server Architecture**: Scalable AI processing
- **Modular Design**: Easy to extend and customize
- **Async Processing**: High performance concurrent handling
- **Fallback Systems**: Graceful degradation on failures

## ğŸ“ˆ Deployment

### Local Development

- Suitable for development and testing
- 200 concurrent users maximum
- Home internet limitations

### Production Server

- 5-25x higher capacity (1000-5000 users)
- 2-3x faster response times
- Enterprise-grade reliability
- Professional monitoring

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- OpenAI for GPT and Whisper APIs
- Microsoft for Edge TTS
- All contributors and testers

---

**Status: âœ… Production Ready**
**Last Updated: June 10, 2025**
**Version: 2.0 (User Modes + Performance Tested)**
