"""Memory management and session testing for Gaja server.

Tests for memory persistence, user sessions, and learning capabilities.
"""

import asyncio
import time
from datetime import datetime

import pytest

# Import test fixtures and helpers


class TestMemoryManager:
    """ðŸ§  5.

    PamiÄ™Ä‡ (memory manager)
    """

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_short_term_memory_persistence(
        self, http_session, server_helper, test_user_id
    ):
        """Short-term memory trzyma dane ok.

        15â€“20 minut
        """
        # Store information in short-term memory
        query1 = "Zapisz w pamiÄ™ci Å¼e lubiÄ™ kawÄ™"
        response1 = await server_helper.make_query_request(
            http_session, test_user_id, query1
        )
        assert "ai_response" in response1

        # Immediately ask about stored information
        query2 = "Co lubiÄ™ piÄ‡?"
        response2 = await server_helper.make_query_request(
            http_session, test_user_id, query2
        )
        assert "ai_response" in response2

        # Response should reference the stored information
        # Note: This requires the server to actually implement memory
        assert len(response2["ai_response"]) > 0

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_mid_term_memory_daily_reset(
        self, http_session, server_helper, test_user_id
    ):
        """Mid-term memory trzyma dane dzienne (reset po pÃ³Å‚nocy lub rÄ™cznie)"""
        # Store daily information
        query = "Dzisiaj miaÅ‚em spotkanie o 14:00"
        response = await server_helper.make_query_request(
            http_session, test_user_id, query
        )
        assert "ai_response" in response

        # Query about today's events
        query2 = "Co robiÅ‚em dzisiaj?"
        response2 = await server_helper.make_query_request(
            http_session, test_user_id, query2
        )
        assert "ai_response" in response2

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_long_term_memory_persistence(
        self, http_session, server_helper, test_user_id
    ):
        """Long-term memory zapisuje do bazy (SQLite) i odczytuje przy starcie."""
        # Store important information for long-term memory
        query = "ZapamiÄ™taj na dÅ‚ugo: moje ulubione miasto to KrakÃ³w"
        response = await server_helper.make_query_request(
            http_session, test_user_id, query, {"memory_type": "long_term"}
        )
        assert "ai_response" in response

        # This would need to be tested across server restarts
        # For now, just verify the response acknowledges storage

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_memory_fallback_handling(
        self, http_session, server_helper, test_user_id
    ):
        """Fallback do â€žbrak pamiÄ™ci" nie crashuje odpowiedzi."""
        # Query about non-existent memory
        query = "Co mÃ³wiÅ‚em wczoraj o nieistniejÄ…cym temacie xyz123?"
        response = await server_helper.make_query_request(
            http_session, test_user_id, query
        )

        assert "ai_response" in response
        assert len(response["ai_response"]) > 0
        # Should gracefully handle lack of memory


class TestHabitLearning:
    """ðŸ“š 6.

    Nauka nawykÃ³w
    """

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_habit_recognition(self, http_session, server_helper, test_user_id):
        """System zapisuje powtarzalne zapytania i pory dnia."""
        # Simulate repeating behavior
        morning_query = "Jaka jest pogoda?"

        # Make the same query multiple times to establish pattern
        for i in range(3):
            response = await server_helper.make_query_request(
                http_session,
                test_user_id,
                morning_query,
                {"timestamp": datetime.now().isoformat()},
            )
            assert "ai_response" in response
            await asyncio.sleep(0.1)  # Small delay

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_habit_suggestions(self, http_session, server_helper, test_user_id):
        """Potrafi zasugerowaÄ‡ automatyczne akcje."""
        # After establishing pattern, ask for suggestions
        query = "Masz jakieÅ› sugestie dla mnie?"
        response = await server_helper.make_query_request(
            http_session, test_user_id, query
        )

        assert "ai_response" in response
        # Response should potentially include suggestions based on patterns

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_behavior_logging(self, http_session, server_helper, test_user_id):
        """Zachowania sÄ… logowane (czas + treÅ›Ä‡ + intencja)"""
        queries = [
            "SprawdÅº email",
            "Jaka jest pogoda?",
            "Ustaw alarm na 7:00",
        ]

        for query in queries:
            response = await server_helper.make_query_request(
                http_session,
                test_user_id,
                query,
                {"timestamp": datetime.now().isoformat()},
            )
            assert "ai_response" in response


class TestAIAndLLMFallback:
    """ðŸ§  7.

    Model AI / LLM fallback
    """

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_gpt_nano_backend(self, http_session, server_helper, test_user_id):
        """DziaÅ‚a gpt-4.1-nano jako domyÅ›lny backend."""
        # Query that should trigger LLM
        query = "Opowiedz mi krÃ³tkÄ… historiÄ™ o robotach"
        response = await server_helper.make_query_request(
            http_session, test_user_id, query
        )

        assert "ai_response" in response
        assert len(response["ai_response"]) > 50  # Should be a decent response

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_api_error_handling(self, http_session, server_helper, test_user_id):
        """ObsÅ‚uga bÅ‚Ä™dÃ³w API (rate limit, 401, brak poÅ‚Ä…czenia)"""
        # Test with potentially problematic query
        query = "Generate a very long response" * 10  # Might hit limits

        try:
            response = await server_helper.make_query_request(
                http_session, test_user_id, query
            )
            # Should either succeed or handle gracefully
            assert "ai_response" in response
        except Exception:
            # Server should handle API errors gracefully
            pass

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_fallback_metadata(self, http_session, server_helper, test_user_id):
        """OdpowiedÅº fallbacka zawiera meta-info (Å¼e to fallback)"""
        # Query that likely uses fallback
        query = "Explain quantum physics in simple terms"
        response = await server_helper.make_query_request(
            http_session, test_user_id, query
        )

        assert "ai_response" in response
        # Check if metadata indicates fallback usage
        if "metadata" in response or "source" in response:
            # Metadata should indicate LLM/fallback usage
            pass

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_token_limit_handling(
        self, http_session, server_helper, test_user_id
    ):
        """Token limit i retry policy dziaÅ‚ajÄ… poprawnie."""
        # Create a query that might hit token limits but is reasonable
        long_query = (
            "Explain machine learning concepts in detail: "
            + "algorithms, neural networks, deep learning, " * 20
        )

        try:
            response = await server_helper.make_query_request(
                http_session, test_user_id, long_query
            )

            assert "ai_response" in response
            # Should handle long queries without crashing
            assert len(response["ai_response"]) > 0

        except TimeoutError:
            # Acceptable - server may timeout on very long queries
            # This is proper error handling behavior
            pass


class TestSessionAndUserLogic:
    """ðŸ“¦ 8.

    Logika sesji i uÅ¼ytkownikÃ³w
    """

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_separate_user_sessions(self, http_session, server_helper):
        """KaÅ¼dy uÅ¼ytkownik ma odrÄ™bnÄ… sesjÄ™ (UUID / token)"""
        user1_id = "session_test_user_1"
        user2_id = "session_test_user_2"

        # User 1 stores information
        response1 = await server_helper.make_query_request(
            http_session, user1_id, "ZapamiÄ™taj Å¼e lubiÄ™ pizzÄ™"
        )
        assert "ai_response" in response1

        # User 2 asks about user 1's information - should not have access
        response2 = await server_helper.make_query_request(
            http_session, user2_id, "Co lubi user1?"
        )
        assert "ai_response" in response2

        # User 2 should not know about user 1's preferences

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_no_data_mixing(self, http_session, server_helper):
        """Dane nie mieszajÄ… siÄ™ miÄ™dzy uÅ¼ytkownikami."""
        user1_id = "data_isolation_user_1"
        user2_id = "data_isolation_user_2"

        # Both users store different information
        await server_helper.make_query_request(
            http_session, user1_id, "Moja ulubiona liczba to 42"
        )

        await server_helper.make_query_request(
            http_session, user2_id, "Moja ulubiona liczba to 100"
        )

        # Each user should get their own information back
        response1 = await server_helper.make_query_request(
            http_session, user1_id, "Jaka jest moja ulubiona liczba?"
        )

        response2 = await server_helper.make_query_request(
            http_session, user2_id, "Jaka jest moja ulubiona liczba?"
        )

        assert "ai_response" in response1
        assert "ai_response" in response2

        # Responses should be different (or at least isolated)

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_multiple_active_users(self, http_session, server_helper):
        """Serwer potrafi trzymaÄ‡ kilka aktywnych uÅ¼ytkownikÃ³w naraz."""
        users = [f"concurrent_user_{i}" for i in range(5)]

        # All users make requests simultaneously
        tasks = []
        for user_id in users:
            task = server_helper.make_query_request(
                http_session, user_id, f"Hello from {user_id}"
            )
            tasks.append(task)

        responses = await asyncio.gather(*tasks)

        # All requests should succeed
        assert len(responses) == 5
        for response in responses:
            assert "ai_response" in response

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_user_switching_simulation(self, http_session, server_helper):
        """MoÅ¼na przeÅ‚Ä…czaÄ‡ uÅ¼ytkownika (symulacja z klienta)"""
        # Simulate client switching between users
        user1_id = "switch_test_user_1"
        user2_id = "switch_test_user_2"

        # Request as user 1
        response1 = await server_helper.make_query_request(
            http_session, user1_id, "Test jako user 1"
        )
        assert "ai_response" in response1

        # Switch to user 2
        response2 = await server_helper.make_query_request(
            http_session, user2_id, "Test jako user 2"
        )
        assert "ai_response" in response2

        # Switch back to user 1
        response3 = await server_helper.make_query_request(
            http_session, user1_id, "Znowu jako user 1"
        )
        assert "ai_response" in response3

        # All should work independently


class TestExtendedScenarios:
    """ðŸ§ª Extended test scenarios."""

    @pytest.mark.asyncio
    @pytest.mark.integration
    @pytest.mark.slow
    async def test_plugin_memory_immediate_use(
        self, http_session, server_helper, test_user_id
    ):
        """OdpowiedÅº z pluginu + zapis wspomnienia + natychmiastowe uÅ¼ycie tej
        wiedzy."""
        # Get weather (plugin response) and store it
        response1 = await server_helper.make_query_request(
            http_session, test_user_id, "Jaka jest pogoda? ZapamiÄ™taj odpowiedÅº."
        )
        assert "ai_response" in response1

        # Immediately ask about stored weather information
        response2 = await server_helper.make_query_request(
            http_session, test_user_id, "JakÄ… pogodÄ™ sprawdzaÅ‚em przed chwilÄ…?"
        )
        assert "ai_response" in response2

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_plugin_fallback_chain(
        self, http_session, server_helper, test_user_id
    ):
        """Brak odpowiedzi z pluginu â†’ fallback do LLM."""
        # Query that might fail plugin but should get LLM response
        query = "Explain the philosophical implications of artificial intelligence"
        response = await server_helper.make_query_request(
            http_session, test_user_id, query
        )

        assert "ai_response" in response
        assert len(response["ai_response"]) > 20  # Should get substantial LLM response

    @pytest.mark.asyncio
    @pytest.mark.performance
    async def test_response_time_consistency(
        self, http_session, server_helper, test_user_id
    ):
        """Test consistent response times across multiple requests."""
        queries = [
            "Jaka jest pogoda?",  # Plugin
            "What time is it?",  # Plugin
            "Tell me a joke",  # LLM
            "Explain physics",  # LLM
        ]

        response_times = []

        for query in queries:
            start_time = time.time()
            response = await server_helper.make_query_request(
                http_session, test_user_id, query
            )
            end_time = time.time()

            assert "ai_response" in response
            response_times.append(end_time - start_time)

        # Check that response times are reasonable
        for rt in response_times:
            assert rt < 5.0, f"Response time {rt}s too slow"

        # Standard deviation should not be too high (consistency)
        import statistics

        if len(response_times) > 1:
            stdev = statistics.stdev(response_times)
            assert stdev < 2.0, f"Response time inconsistency: stdev={stdev}s"


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])
