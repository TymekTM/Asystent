# Testy GAJA Assistant

Ten katalog zawiera kompleksowy zestaw testÃ³w dla systemu GAJA Assistant, obejmujÄ…cy zarÃ³wno serwer jak i klient.

## Struktura testÃ³w

```
tests_pytest/
â”œâ”€â”€ conftest.py              # Konfiguracja pytest i fixtures
â”œâ”€â”€ test_server.py           # Testy serwera
â”œâ”€â”€ test_client.py           # Testy klienta
â”œâ”€â”€ test_integration.py      # Testy integracyjne
â”œâ”€â”€ test_performance.py      # Testy wydajnoÅ›ci
â””â”€â”€ test_audio.py           # Testy komponentÃ³w audio
```

## Typy testÃ³w

### ğŸ”§ Testy jednostkowe (Unit Tests)
- **Marker**: `@pytest.mark.unit`
- **Plik**: `test_server.py`, `test_client.py`
- **Opis**: TestujÄ… pojedyncze komponenty w izolacji

### ğŸ”— Testy integracyjne (Integration Tests)
- **Marker**: `@pytest.mark.integration`
- **Plik**: `test_integration.py`
- **Opis**: TestujÄ… komunikacjÄ™ miÄ™dzy komponentami

### âš¡ Testy wydajnoÅ›ci (Performance Tests)
- **Marker**: `@pytest.mark.performance`
- **Plik**: `test_performance.py`
- **Opis**: TestujÄ… wydajnoÅ›Ä‡ i stabilnoÅ›Ä‡ pod obciÄ…Å¼eniem

### ğŸµ Testy audio (Audio Tests)
- **Marker**: `@pytest.mark.audio`
- **Plik**: `test_audio.py`
- **Opis**: TestujÄ… komponenty audio (wakeword, ASR, TTS)

### ğŸŒ Testy powolne (Slow Tests)
- **Marker**: `@pytest.mark.slow`
- **Opis**: DÅ‚ugotrwaÅ‚e testy, wyÅ‚Ä…czane domyÅ›lnie

## Instalacja zaleÅ¼noÅ›ci

```bash
# Zainstaluj zaleÅ¼noÅ›ci testowe
pip install -r requirements_test.txt

# Lub uÅ¼yj skryptu
python run_tests.py install
```

## Uruchamianie testÃ³w

### Podstawowe uÅ¼ycie

```bash
# Wszystkie testy
python run_tests.py run

# Tylko testy jednostkowe
python run_tests.py run --type unit

# Tylko testy integracyjne
python run_tests.py run --type integration

# Tylko testy wydajnoÅ›ci
python run_tests.py run --type performance

# Tylko testy audio
python run_tests.py run --type audio
```

### Opcje zaawansowane

```bash
# Z pokryciem kodu
python run_tests.py run --coverage

# RÃ³wnolegÅ‚e wykonywanie
python run_tests.py run --parallel

# SzczegÃ³Å‚owe informacje
python run_tests.py run --verbose

# Szybkie testy (bez powolnych)
python run_tests.py run --type fast

# Konkretny plik testowy
python run_tests.py file --file test_server.py
```

### UÅ¼ycie bezpoÅ›rednio pytest

```bash
# Wszystkie testy
pytest tests_pytest/

# Konkretne markery
pytest tests_pytest/ -m unit
pytest tests_pytest/ -m "unit and not slow"
pytest tests_pytest/ -m "server or client"

# Z pokryciem
pytest tests_pytest/ --cov=server --cov=client --cov-report=html

# RÃ³wnolegle
pytest tests_pytest/ -n auto
```

## Konfiguracja Å›rodowiska

### Sprawdzenie Å›rodowiska
```bash
python run_tests.py check
```

### Odkrywanie testÃ³w
```bash
python run_tests.py discover
```

### Generowanie raportÃ³w
```bash
python run_tests.py report
```

## Markery testÃ³w

| Marker | Opis |
|--------|------|
| `unit` | Testy jednostkowe |
| `integration` | Testy integracyjne |
| `server` | Testy serwera |
| `client` | Testy klienta |
| `websocket` | Testy WebSocket |
| `database` | Testy bazy danych |
| `ai` | Testy moduÅ‚Ã³w AI |
| `audio` | Testy komponentÃ³w audio |
| `plugin` | Testy systemu pluginÃ³w |
| `performance` | Testy wydajnoÅ›ci |
| `slow` | Powolne testy |

## Fixtures dostÄ™pne

### Podstawowe
- `event_loop` - PÄ™tla zdarzeÅ„ asyncio
- `temp_config_dir` - Tymczasowy katalog konfiguracji
- `mock_config` - Mock konfiguracji
- `mock_db_manager` - Mock menedÅ¼era bazy danych
- `mock_ai_module` - Mock moduÅ‚u AI
- `mock_websocket` - Mock poÅ‚Ä…czenia WebSocket

### Aplikacje
- `server_app` - Instancja ServerApp
- `client_app` - Instancja ClientApp

### Audio
- `mock_audio_components` - Mock komponentÃ³w audio
- `mock_plugin` - Mock pluginu

### Dane testowe
- `sample_chat_data` - PrzykÅ‚adowe dane czatu
- `sample_plugin_data` - PrzykÅ‚adowe dane pluginÃ³w

## PrzykÅ‚ady uÅ¼ycia

### Test jednostkowy
```python
@pytest.mark.unit
def test_connection_manager_init():
    manager = ConnectionManager()
    assert manager.active_connections == {}
```

### Test integracyjny
```python
@pytest.mark.integration
@pytest.mark.asyncio
async def test_websocket_communication(server_app, client_app):
    # Test komunikacji klient-serwer
    response = await server_app.process_user_request(user_id, message)
    assert response["type"] == "ai_response"
```

### Test audio
```python
@pytest.mark.audio
@pytest.mark.asyncio
async def test_whisper_transcription(mock_audio_components):
    asr = mock_audio_components["whisper_asr"]
    result = await asr.transcribe(audio_data)
    assert result == "Expected transcription"
```

### Test wydajnoÅ›ci
```python
@pytest.mark.performance
@pytest.mark.slow
@pytest.mark.asyncio
async def test_high_frequency_requests(server_app):
    # Test wielu requestÃ³w
    for i in range(100):
        response = await server_app.process_user_request(user_id, request)
        assert response["type"] == "ai_response"
```

## Raporty testÃ³w

### HTML Report
Po uruchomieniu z `--coverage` dostÄ™pny w `htmlcov/index.html`

### JSON Report
Po uruchomieniu z `python run_tests.py report` dostÄ™pny w `test_report.json`

### XML Report
Dla integracji CI/CD w `coverage.xml`

## Debugging testÃ³w

### Uruchomienie jednego testu
```bash
pytest tests_pytest/test_server.py::TestConnectionManager::test_connect_user -v
```

### Z debuggerem
```bash
pytest tests_pytest/test_server.py::test_specific_function --pdb
```

### Z logami
```bash
pytest tests_pytest/ --log-cli-level=DEBUG
```

## Integracja CI/CD

### GitHub Actions
```yaml
- name: Run tests
  run: |
    python run_tests.py install
    python run_tests.py run --type unit --coverage
    python run_tests.py run --type integration
```

### Coverage Badge
UÅ¼ywa pliku `coverage.xml` do generowania badge pokrycia kodu.

## Najlepsze praktyki

1. **UÅ¼ywaj odpowiednich markerÃ³w** dla kategoryzacji testÃ³w
2. **Mock zewnÄ™trzne zaleÅ¼noÅ›ci** w testach jednostkowych
3. **Testuj happy path i edge cases** 
4. **UÅ¼ywaj fixtures** dla wspÃ³lnych setupÃ³w
5. **Nazywaj testy opisowo** - `test_should_do_something_when_condition`
6. **Grupuj testy w klasy** dla lepszej organizacji
7. **UÅ¼ywaj async/await** dla testÃ³w asynchronicznych
8. **Sprawdzaj nie tylko sukces** ale teÅ¼ odpowiednie bÅ‚Ä™dy

## RozwiÄ…zywanie problemÃ³w

### Import errors
- SprawdÅº czy `PYTHONPATH` zawiera odpowiednie katalogi
- Uruchom `python run_tests.py check`

### BÅ‚Ä™dy audio testÃ³w
- SprawdÅº czy wszystkie mock komponenty sÄ… skonfigurowane
- SprawdÅº czy system ma dostÄ™p do urzÄ…dzeÅ„ audio (dla testÃ³w integracyjnych)

### Timeouty
- UÅ¼yj `@pytest.mark.timeout(30)` dla dÅ‚ugich testÃ³w
- SprawdÅº czy nie ma deadlockÃ³w w kodzie asynchronicznym

### Problemy z fixtures
- SprawdÅº scope fixtures (`session`, `module`, `function`)
- Upewnij siÄ™ Å¼e fixtures sÄ… importowane w `conftest.py`
